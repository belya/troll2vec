{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_columns = [c for c in train_df.columns if c not in [\"comment_text\", \"id\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"toxic\"] = train_df[classes_columns].any(axis=1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exploitative and largely devoid of the depth or sophistication that would make watching such a graphic treatment of the crimes bearable . \n",
    "# linebreaks, contractions\n",
    "\n",
    "ip_regex = re.compile(\"\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\")\n",
    "time_regex = re.compile(\"\")\n",
    "symbols_regex = re.compile(\"([.?!,:\\\"]+)\")\n",
    "spaces_regex = re.compile(\"\\s+\")\n",
    "brackets_regex = re.compile(\"[()]\")\n",
    "\n",
    "def preprocess_comment(comment):\n",
    "    comment = ip_regex.sub(\"\", comment)\n",
    "    comment = comment.replace(\"\\n\", \" \").lower()\n",
    "    comment = symbols_regex.sub(\" \\\\1 \", comment)\n",
    "    comment = brackets_regex.sub(\" \", comment)\n",
    "    comment = spaces_regex.sub(\" \", comment)\n",
    "    return comment.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"preprocessed_comment\"] = train_df[\"comment_text\"].apply(preprocess_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"length\"] = train_df[\"preprocessed_comment\"].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[train_df[\"length\"] <= 400].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translate posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from tqdm import tqdm_notebook\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "YANDEX_SESSION_API_KEY = \"6e35a458.5c7bbf99.b921cfd7-1-0\" #os.environ[\"YANDEX_SESSION_API_KEY\"]\n",
    "YANDEX_URL =\"https://translate.yandex.net/api/v1/tr.json/translate?id={}&srv=tr-text&lang=en-ru&reason=auto\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(text):\n",
    "    url = YANDEX_URL.format(YANDEX_SESSION_API_KEY)\n",
    "    response = requests.post(url, data={\"text\": text, \"options\": 4}).json()\n",
    "    if \"message\" in response:\n",
    "        print(response[\"message\"])\n",
    "    return response[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks(l, n):\n",
    "    \"\"\"Yield successive n-sized chunks from l.\"\"\"\n",
    "    for i in range(0, len(l), n):\n",
    "        yield l[i:i + n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "end_of_comment = \"EOCOMMENT\\n\"\n",
    "all_translations = []\n",
    "all_texts = train_df[\"comment_text\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7a8490d2ba34633b4b6003e4a608cbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=26762), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for text in tqdm_notebook(all_texts[index:]):\n",
    "    translation = translate(text[0:600])\n",
    "    index += 1\n",
    "    all_translations.append(translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"translated_comment\"] = [text[0] for text in all_translations]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/toxicity.pos', \"w\") as file:\n",
    "    for comment in train_df[train_df[\"toxic\"] == 1][\"translated_comment\"]:\n",
    "        file.write(comment + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/toxicity.neg', \"w\") as file:\n",
    "    for comment in train_df[train_df[\"toxic\"] == 0][\"translated_comment\"]:\n",
    "        file.write(comment + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
